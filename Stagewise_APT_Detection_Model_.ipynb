{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9257ba7b-134d-4adb-8e9b-88bc94d77baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# --- Configuration ---\n",
    "TRAIN_PATH = \"UNSW_NB15_APT_features_train.csv\"\n",
    "TEST_PATH  = \"UNSW_NB15_APT_features_test.csv\"\n",
    "\n",
    "# Helper function for sparse matrices\n",
    "def to_dense(X):\n",
    "    return X.toarray() if hasattr(X, \"toarray\") else X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866553ec-57c1-4e58-afc0-53498cb34a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Shape: (175341, 37)\n",
      "Original Test Shape: (82332, 37)\n",
      "\n",
      "TRAIN stage distribution:\n",
      " APT_stage\n",
      "Normal     56000\n",
      "Exploit    52264\n",
      "Initial    33393\n",
      "Recon      30675\n",
      "Install     3009\n",
      "Name: count, dtype: int64\n",
      "\n",
      "TEST stage distribution:\n",
      " APT_stage\n",
      "Normal     37000\n",
      "Exploit    22960\n",
      "Initial    11132\n",
      "Recon      10235\n",
      "Install     1005\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"Original Train Shape:\", train_df.shape)\n",
    "print(\"Original Test Shape:\", test_df.shape)\n",
    "\n",
    "# --- Map Attacks to APT Stages ---\n",
    "stage_mapping = {\n",
    "    \"Reconnaissance\": \"Recon\", \n",
    "    \"Fuzzers\": \"Recon\", \n",
    "    \"Analysis\": \"Recon\",\n",
    "    \"Exploits\": \"Initial\", \n",
    "    \"DoS\": \"Exploit\", \n",
    "    \"Generic\": \"Exploit\",\n",
    "    \"Backdoor\": \"Install\", \n",
    "    \"Shellcode\": \"Install\", \n",
    "    \"Worms\": \"Install\",\n",
    "    \"Normal\": \"Normal\"\n",
    "}\n",
    "\n",
    "train_df[\"APT_stage\"] = train_df[\"attack_cat\"].map(stage_mapping)\n",
    "test_df[\"APT_stage\"]  = test_df[\"attack_cat\"].map(stage_mapping)\n",
    "\n",
    "print(\"\\nTRAIN stage distribution:\\n\", train_df[\"APT_stage\"].value_counts())\n",
    "print(\"\\nTEST stage distribution:\\n\", test_df[\"APT_stage\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17be8fd-f14f-4ab8-96a8-1adcf237958b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global preprocessor fitted successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Feature Engineering ---\n",
    "meta_cols = [\"attack_cat\", \"label\", \"APT_stage\"]\n",
    "feature_cols = [c for c in train_df.columns if c not in meta_cols]\n",
    "\n",
    "X_full_train = train_df[feature_cols]\n",
    "\n",
    "numeric_features = X_full_train.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "categorical_features = X_full_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# Define Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit on full training feature space\n",
    "preprocessor.fit(X_full_train)\n",
    "print(\"Global preprocessor fitted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db67ddf4-1ec9-4e87-845f-91a743b7968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splitting function defined.\n"
     ]
    }
   ],
   "source": [
    "def create_stagewise_datasets(train_df, test_df):\n",
    "    datasets = {}\n",
    "    \n",
    "    # Logic: (Key Name, Target Class, Class to Remove from Dataset)\n",
    "    definitions = [\n",
    "        (\"stage0_attack\", \"Normal\", None),              # Attack vs Normal (Target is NOT Normal)\n",
    "        (\"stage1_recon\", \"Recon\", None),                # Recon vs Others\n",
    "        (\"stage2_initial\", \"Initial\", \"Recon\"),         # Initial vs Others (Remove Recon)\n",
    "        (\"stage3_exploit\", \"Exploit\", \"Initial\"),       # Exploit vs Others (Remove Initial)\n",
    "        (\"stage4_install\", \"Install\", \"Exploit\")        # Install vs Others (Remove Exploit)\n",
    "    ]\n",
    "\n",
    "    for key, target_class, class_to_remove in definitions:\n",
    "        current_train = train_df.copy()\n",
    "        current_test = test_df.copy()\n",
    "\n",
    "        if class_to_remove:\n",
    "            current_train = current_train[current_train[\"APT_stage\"] != class_to_remove]\n",
    "            current_test  = current_test[current_test[\"APT_stage\"] != class_to_remove]\n",
    "            \n",
    "        # Create Binary Labels\n",
    "        if key == \"stage0_attack\":\n",
    "            # For Stage 0, we want 1 if it is an ATTACK (not Normal)\n",
    "            current_train[\"stage_label\"] = (current_train[\"APT_stage\"] != \"Normal\").astype(int)\n",
    "            current_test[\"stage_label\"]  = (current_test[\"APT_stage\"] != \"Normal\").astype(int)\n",
    "        else:\n",
    "            # For other stages, 1 if it matches the specific stage\n",
    "            current_train[\"stage_label\"] = (current_train[\"APT_stage\"] == target_class).astype(int)\n",
    "            current_test[\"stage_label\"]  = (current_test[\"APT_stage\"] == target_class).astype(int)\n",
    "\n",
    "        datasets[key] = {\"train\": current_train, \"test\": current_test}\n",
    "\n",
    "    return datasets\n",
    "\n",
    "print(\"Dataset splitting function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "278dfaad-dfd1-47b0-85c4-d5532a7971f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing stage0_attack...\n",
      "  -> Original shape: (175341, 187), Balanced shape: (238682, 187)\n",
      "Balancing stage1_recon...\n",
      "  -> Original shape: (175341, 187), Balanced shape: (289332, 187)\n",
      "Balancing stage2_initial...\n",
      "  -> Original shape: (144666, 187), Balanced shape: (222546, 187)\n",
      "Balancing stage3_exploit...\n",
      "  -> Original shape: (141948, 187), Balanced shape: (179368, 187)\n",
      "Balancing stage4_install...\n",
      "  -> Original shape: (123077, 187), Balanced shape: (240136, 187)\n",
      "\n",
      "All datasets balanced and ready.\n"
     ]
    }
   ],
   "source": [
    "def make_balanced_stage(stage_key, datasets, preprocessor, feature_cols):\n",
    "    data = datasets[stage_key]\n",
    "    \n",
    "    # Transform features\n",
    "    X_train = to_dense(preprocessor.transform(data[\"train\"][feature_cols]))\n",
    "    y_train = data[\"train\"][\"stage_label\"].values\n",
    "    \n",
    "    X_test  = to_dense(preprocessor.transform(data[\"test\"][feature_cols]))\n",
    "    y_test  = data[\"test\"][\"stage_label\"].values\n",
    "\n",
    "    print(f\"Balancing {stage_key}...\")\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(f\"  -> Original shape: {X_train.shape}, Balanced shape: {X_train_bal.shape}\")\n",
    "    \n",
    "    return {\n",
    "        \"X_train_bal\": X_train_bal, \n",
    "        \"y_train_bal\": y_train_bal,\n",
    "        \"X_test\": X_test, \n",
    "        \"y_test\": y_test\n",
    "    }\n",
    "\n",
    "# Execute creation and balancing\n",
    "datasets = create_stagewise_datasets(train_df, test_df)\n",
    "balanced_sets = {}\n",
    "stage_keys = [\"stage0_attack\", \"stage1_recon\", \"stage2_initial\", \"stage3_exploit\", \"stage4_install\"]\n",
    "\n",
    "for key in stage_keys:\n",
    "    balanced_sets[key] = make_balanced_stage(key, datasets, preprocessor, feature_cols)\n",
    "    \n",
    "print(\"\\nAll datasets balanced and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa41526e-2751-429a-848d-3b88e8898c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture and training loop defined.\n"
     ]
    }
   ],
   "source": [
    "def build_stage_model(input_dim, l2_reg=1e-4, dropout_rate=0.3):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def train_stage(X_train, y_train, X_test, y_test, stage_name, \n",
    "                base_weights_path=None, save_weights_path=None, \n",
    "                frozen_epochs=15, finetune_epochs=5, class_weights=None):\n",
    "    \n",
    "    input_dim = X_train.shape[1]\n",
    "    model = build_stage_model(input_dim)\n",
    "\n",
    "    # --- Transfer Learning Logic ---\n",
    "    if base_weights_path:\n",
    "        print(f\"\\n[{stage_name}] Loading base weights from {base_weights_path}...\")\n",
    "        model.load_weights(base_weights_path)\n",
    "        \n",
    "        # 1. Freeze layers\n",
    "        for layer in model.layers[:-1]: layer.trainable = False\n",
    "        \n",
    "        model.compile(optimizer=keras.optimizers.Adam(5e-4), loss=\"binary_crossentropy\", \n",
    "                      metrics=[\"accuracy\", keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "        \n",
    "        print(f\"[{stage_name}] Training frozen layers...\")\n",
    "        model.fit(X_train, y_train, validation_split=0.1, epochs=frozen_epochs, \n",
    "                  batch_size=256, verbose=1, class_weight=class_weights)\n",
    "        \n",
    "        # 2. Unfreeze\n",
    "        for layer in model.layers: layer.trainable = True\n",
    "        print(f\"[{stage_name}] Fine-tuning all layers...\")\n",
    "        \n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-4 if base_weights_path else 1e-3),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_split=0.1, \n",
    "              epochs=finetune_epochs if base_weights_path else 20, \n",
    "              batch_size=256, callbacks=[early_stop], verbose=1, class_weight=class_weights)\n",
    "\n",
    "    if save_weights_path:\n",
    "        model.save_weights(save_weights_path)\n",
    "        print(f\"[{stage_name}] Weights saved to {save_weights_path}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "print(\"Model architecture and training loop defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97bf7c46-ca68-4b61-b44d-c3cbe0a9cc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "840/840 [==============================] - 10s 9ms/step - loss: 0.1854 - accuracy: 0.9221 - precision: 0.9180 - recall: 0.9441 - val_loss: 0.1659 - val_accuracy: 0.9351 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/20\n",
      "840/840 [==============================] - 6s 7ms/step - loss: 0.1503 - accuracy: 0.9319 - precision: 0.9359 - recall: 0.9418 - val_loss: 0.1563 - val_accuracy: 0.9354 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/20\n",
      "840/840 [==============================] - 6s 7ms/step - loss: 0.1421 - accuracy: 0.9343 - precision: 0.9389 - recall: 0.9431 - val_loss: 0.1742 - val_accuracy: 0.9145 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/20\n",
      "840/840 [==============================] - 6s 8ms/step - loss: 0.1379 - accuracy: 0.9358 - precision: 0.9408 - recall: 0.9439 - val_loss: 0.1683 - val_accuracy: 0.9116 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/20\n",
      "840/840 [==============================] - 7s 8ms/step - loss: 0.1353 - accuracy: 0.9363 - precision: 0.9414 - recall: 0.9442 - val_loss: 0.1673 - val_accuracy: 0.9213 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "[Stage 0] Weights saved to stage0.h5\n",
      "\n",
      "[Stage 1] Loading base weights from stage0.h5...\n",
      "[Stage 1] Training frozen layers...\n",
      "Epoch 1/15\n",
      "1018/1018 [==============================] - 9s 6ms/step - loss: 1.3098 - accuracy: 0.5540 - precision_1: 0.4982 - recall_1: 0.4749 - val_loss: 0.7892 - val_accuracy: 0.4016 - val_precision_1: 1.0000 - val_recall_1: 0.4016\n",
      "Epoch 2/15\n",
      "1018/1018 [==============================] - 6s 5ms/step - loss: 0.4969 - accuracy: 0.7453 - precision_1: 0.8067 - recall_1: 0.5616 - val_loss: 0.6454 - val_accuracy: 0.6385 - val_precision_1: 1.0000 - val_recall_1: 0.6385\n",
      "Epoch 3/15\n",
      "1018/1018 [==============================] - 6s 6ms/step - loss: 0.4599 - accuracy: 0.8031 - precision_1: 0.8053 - recall_1: 0.7346 - val_loss: 0.5620 - val_accuracy: 0.7693 - val_precision_1: 1.0000 - val_recall_1: 0.7693\n",
      "Epoch 4/15\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.4401 - accuracy: 0.8161 - precision_1: 0.7898 - recall_1: 0.7989 - val_loss: 0.5070 - val_accuracy: 0.8140 - val_precision_1: 1.0000 - val_recall_1: 0.8140\n",
      "Epoch 5/15\n",
      "1018/1018 [==============================] - 6s 6ms/step - loss: 0.4281 - accuracy: 0.8151 - precision_1: 0.7757 - recall_1: 0.8215 - val_loss: 0.4724 - val_accuracy: 0.8237 - val_precision_1: 1.0000 - val_recall_1: 0.8237\n",
      "Epoch 6/15\n",
      "1018/1018 [==============================] - 6s 6ms/step - loss: 0.4212 - accuracy: 0.8122 - precision_1: 0.7657 - recall_1: 0.8321 - val_loss: 0.4453 - val_accuracy: 0.8316 - val_precision_1: 1.0000 - val_recall_1: 0.8316\n",
      "Epoch 7/15\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.4171 - accuracy: 0.8100 - precision_1: 0.7601 - recall_1: 0.8364 - val_loss: 0.4272 - val_accuracy: 0.8342 - val_precision_1: 1.0000 - val_recall_1: 0.8342\n",
      "Epoch 8/15\n",
      "1018/1018 [==============================] - 6s 6ms/step - loss: 0.4153 - accuracy: 0.8083 - precision_1: 0.7561 - recall_1: 0.8394 - val_loss: 0.4037 - val_accuracy: 0.8404 - val_precision_1: 1.0000 - val_recall_1: 0.8404\n",
      "Epoch 9/15\n",
      "1018/1018 [==============================] - 6s 6ms/step - loss: 0.4134 - accuracy: 0.8085 - precision_1: 0.7552 - recall_1: 0.8421 - val_loss: 0.4059 - val_accuracy: 0.8394 - val_precision_1: 1.0000 - val_recall_1: 0.8394\n",
      "Epoch 10/15\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.4131 - accuracy: 0.8076 - precision_1: 0.7534 - recall_1: 0.8431 - val_loss: 0.4090 - val_accuracy: 0.8388 - val_precision_1: 1.0000 - val_recall_1: 0.8388\n",
      "Epoch 11/15\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.4121 - accuracy: 0.8084 - precision_1: 0.7545 - recall_1: 0.8434 - val_loss: 0.3968 - val_accuracy: 0.8422 - val_precision_1: 1.0000 - val_recall_1: 0.8422\n",
      "Epoch 12/15\n",
      "1018/1018 [==============================] - 6s 6ms/step - loss: 0.4116 - accuracy: 0.8078 - precision_1: 0.7533 - recall_1: 0.8441 - val_loss: 0.3955 - val_accuracy: 0.8429 - val_precision_1: 1.0000 - val_recall_1: 0.8429\n",
      "Epoch 13/15\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.4106 - accuracy: 0.8086 - precision_1: 0.7544 - recall_1: 0.8444 - val_loss: 0.3941 - val_accuracy: 0.8438 - val_precision_1: 1.0000 - val_recall_1: 0.8438\n",
      "Epoch 14/15\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.4117 - accuracy: 0.8081 - precision_1: 0.7529 - recall_1: 0.8459 - val_loss: 0.3948 - val_accuracy: 0.8435 - val_precision_1: 1.0000 - val_recall_1: 0.8435\n",
      "Epoch 15/15\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.4103 - accuracy: 0.8084 - precision_1: 0.7531 - recall_1: 0.8464 - val_loss: 0.3926 - val_accuracy: 0.8443 - val_precision_1: 1.0000 - val_recall_1: 0.8443\n",
      "[Stage 1] Fine-tuning all layers...\n",
      "Epoch 1/5\n",
      "1018/1018 [==============================] - 11s 8ms/step - loss: 0.3395 - accuracy: 0.8415 - precision_2: 0.7932 - recall_2: 0.8702 - val_loss: 0.2844 - val_accuracy: 0.8738 - val_precision_2: 1.0000 - val_recall_2: 0.8738\n",
      "Epoch 2/5\n",
      "1018/1018 [==============================] - 8s 8ms/step - loss: 0.3210 - accuracy: 0.8489 - precision_2: 0.8102 - recall_2: 0.8619 - val_loss: 0.2752 - val_accuracy: 0.8574 - val_precision_2: 1.0000 - val_recall_2: 0.8574\n",
      "Epoch 3/5\n",
      "1018/1018 [==============================] - 8s 8ms/step - loss: 0.3153 - accuracy: 0.8512 - precision_2: 0.8168 - recall_2: 0.8574 - val_loss: 0.2718 - val_accuracy: 0.8443 - val_precision_2: 1.0000 - val_recall_2: 0.8443\n",
      "Epoch 4/5\n",
      "1018/1018 [==============================] - 8s 7ms/step - loss: 0.3115 - accuracy: 0.8529 - precision_2: 0.8228 - recall_2: 0.8527 - val_loss: 0.2872 - val_accuracy: 0.8380 - val_precision_2: 1.0000 - val_recall_2: 0.8380\n",
      "Epoch 5/5\n",
      "1018/1018 [==============================] - 8s 8ms/step - loss: 0.3082 - accuracy: 0.8551 - precision_2: 0.8277 - recall_2: 0.8512 - val_loss: 0.2649 - val_accuracy: 0.8503 - val_precision_2: 1.0000 - val_recall_2: 0.8503\n",
      "[Stage 1] Weights saved to stage1.h5\n",
      "\n",
      "[Stage 2] Loading base weights from stage1.h5...\n",
      "[Stage 2] Training frozen layers...\n",
      "Epoch 1/15\n",
      "783/783 [==============================] - 6s 6ms/step - loss: 1.3022 - accuracy: 0.6840 - precision_3: 0.6697 - recall_3: 0.5704 - val_loss: 1.0987 - val_accuracy: 0.6611 - val_precision_3: 1.0000 - val_recall_3: 0.6611\n",
      "Epoch 2/15\n",
      "783/783 [==============================] - 5s 7ms/step - loss: 0.7907 - accuracy: 0.7244 - precision_3: 0.6795 - recall_3: 0.7192 - val_loss: 0.5810 - val_accuracy: 0.7486 - val_precision_3: 1.0000 - val_recall_3: 0.7486\n",
      "Epoch 3/15\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.5591 - accuracy: 0.7534 - precision_3: 0.7016 - recall_3: 0.7746 - val_loss: 0.3881 - val_accuracy: 0.8085 - val_precision_3: 1.0000 - val_recall_3: 0.8085\n",
      "Epoch 4/15\n",
      "783/783 [==============================] - 5s 6ms/step - loss: 0.4115 - accuracy: 0.8141 - precision_3: 0.7440 - recall_3: 0.8870 - val_loss: 0.3342 - val_accuracy: 0.9882 - val_precision_3: 1.0000 - val_recall_3: 0.9882\n",
      "Epoch 5/15\n",
      "783/783 [==============================] - 5s 6ms/step - loss: 0.3537 - accuracy: 0.8705 - precision_3: 0.7871 - recall_3: 0.9716 - val_loss: 0.3195 - val_accuracy: 0.9850 - val_precision_3: 1.0000 - val_recall_3: 0.9850\n",
      "Epoch 6/15\n",
      "783/783 [==============================] - 4s 6ms/step - loss: 0.3301 - accuracy: 0.8834 - precision_3: 0.8071 - recall_3: 0.9695 - val_loss: 0.3026 - val_accuracy: 0.9721 - val_precision_3: 1.0000 - val_recall_3: 0.9721\n",
      "Epoch 7/15\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3158 - accuracy: 0.8863 - precision_3: 0.8144 - recall_3: 0.9638 - val_loss: 0.2940 - val_accuracy: 0.9673 - val_precision_3: 1.0000 - val_recall_3: 0.9673\n",
      "Epoch 8/15\n",
      "783/783 [==============================] - 4s 6ms/step - loss: 0.3068 - accuracy: 0.8879 - precision_3: 0.8178 - recall_3: 0.9622 - val_loss: 0.2787 - val_accuracy: 0.9653 - val_precision_3: 1.0000 - val_recall_3: 0.9653\n",
      "Epoch 9/15\n",
      "783/783 [==============================] - 4s 6ms/step - loss: 0.3000 - accuracy: 0.8890 - precision_3: 0.8206 - recall_3: 0.9601 - val_loss: 0.2685 - val_accuracy: 0.9645 - val_precision_3: 1.0000 - val_recall_3: 0.9645\n",
      "Epoch 10/15\n",
      "783/783 [==============================] - 4s 6ms/step - loss: 0.2952 - accuracy: 0.8895 - precision_3: 0.8218 - recall_3: 0.9595 - val_loss: 0.2567 - val_accuracy: 0.9641 - val_precision_3: 1.0000 - val_recall_3: 0.9641\n",
      "Epoch 11/15\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.2903 - accuracy: 0.8903 - precision_3: 0.8231 - recall_3: 0.9594 - val_loss: 0.2632 - val_accuracy: 0.9632 - val_precision_3: 1.0000 - val_recall_3: 0.9632\n",
      "Epoch 12/15\n",
      "783/783 [==============================] - 5s 6ms/step - loss: 0.2885 - accuracy: 0.8911 - precision_3: 0.8249 - recall_3: 0.9584 - val_loss: 0.2506 - val_accuracy: 0.9636 - val_precision_3: 1.0000 - val_recall_3: 0.9636\n",
      "Epoch 13/15\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.2868 - accuracy: 0.8912 - precision_3: 0.8250 - recall_3: 0.9585 - val_loss: 0.2364 - val_accuracy: 0.9642 - val_precision_3: 1.0000 - val_recall_3: 0.9642\n",
      "Epoch 14/15\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.2842 - accuracy: 0.8919 - precision_3: 0.8258 - recall_3: 0.9593 - val_loss: 0.2536 - val_accuracy: 0.9629 - val_precision_3: 1.0000 - val_recall_3: 0.9629\n",
      "Epoch 15/15\n",
      "783/783 [==============================] - 5s 6ms/step - loss: 0.2823 - accuracy: 0.8923 - precision_3: 0.8269 - recall_3: 0.9582 - val_loss: 0.2474 - val_accuracy: 0.9632 - val_precision_3: 1.0000 - val_recall_3: 0.9632\n",
      "[Stage 2] Fine-tuning all layers...\n",
      "Epoch 1/5\n",
      "783/783 [==============================] - 8s 8ms/step - loss: 0.2452 - accuracy: 0.9032 - precision_4: 0.8384 - recall_4: 0.9688 - val_loss: 0.2017 - val_accuracy: 0.9783 - val_precision_4: 1.0000 - val_recall_4: 0.9783\n",
      "Epoch 2/5\n",
      "783/783 [==============================] - 5s 7ms/step - loss: 0.2361 - accuracy: 0.9065 - precision_4: 0.8404 - recall_4: 0.9747 - val_loss: 0.1879 - val_accuracy: 0.9803 - val_precision_4: 1.0000 - val_recall_4: 0.9803\n",
      "Epoch 3/5\n",
      "783/783 [==============================] - 5s 7ms/step - loss: 0.2327 - accuracy: 0.9074 - precision_4: 0.8411 - recall_4: 0.9760 - val_loss: 0.1799 - val_accuracy: 0.9848 - val_precision_4: 1.0000 - val_recall_4: 0.9848\n",
      "Epoch 4/5\n",
      "783/783 [==============================] - 6s 7ms/step - loss: 0.2308 - accuracy: 0.9078 - precision_4: 0.8413 - recall_4: 0.9769 - val_loss: 0.1954 - val_accuracy: 0.9786 - val_precision_4: 1.0000 - val_recall_4: 0.9786\n",
      "Epoch 5/5\n",
      "783/783 [==============================] - 5s 7ms/step - loss: 0.2287 - accuracy: 0.9084 - precision_4: 0.8417 - recall_4: 0.9777 - val_loss: 0.1792 - val_accuracy: 0.9816 - val_precision_4: 1.0000 - val_recall_4: 0.9816\n",
      "[Stage 2] Weights saved to stage2.h5\n",
      "\n",
      "[Stage 3] Loading base weights from stage2.h5...\n",
      "[Stage 3] Training frozen layers...\n",
      "Epoch 1/15\n",
      "631/631 [==============================] - 5s 6ms/step - loss: 3.1173 - accuracy: 0.5539 - precision_5: 0.4965 - recall_5: 0.2556 - val_loss: 3.0092 - val_accuracy: 0.2544 - val_precision_5: 1.0000 - val_recall_5: 0.2544\n",
      "Epoch 2/15\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 1.0087 - accuracy: 0.6960 - precision_5: 0.6756 - recall_5: 0.6077 - val_loss: 0.2693 - val_accuracy: 0.8640 - val_precision_5: 1.0000 - val_recall_5: 0.8640\n",
      "Epoch 3/15\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 0.6296 - accuracy: 0.8233 - precision_5: 0.7606 - recall_5: 0.8790 - val_loss: 0.0792 - val_accuracy: 0.9905 - val_precision_5: 1.0000 - val_recall_5: 0.9905\n",
      "Epoch 4/15\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 0.5469 - accuracy: 0.8551 - precision_5: 0.7857 - recall_5: 0.9267 - val_loss: 0.0513 - val_accuracy: 0.9941 - val_precision_5: 1.0000 - val_recall_5: 0.9941\n",
      "Epoch 5/15\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 0.4918 - accuracy: 0.8735 - precision_5: 0.8061 - recall_5: 0.9420 - val_loss: 0.0462 - val_accuracy: 0.9926 - val_precision_5: 1.0000 - val_recall_5: 0.9926\n",
      "Epoch 6/15\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 0.4440 - accuracy: 0.8884 - precision_5: 0.8260 - recall_5: 0.9489 - val_loss: 0.0480 - val_accuracy: 0.9908 - val_precision_5: 1.0000 - val_recall_5: 0.9908\n",
      "Epoch 7/15\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 0.4002 - accuracy: 0.9011 - precision_5: 0.8442 - recall_5: 0.9534 - val_loss: 0.0530 - val_accuracy: 0.9885 - val_precision_5: 1.0000 - val_recall_5: 0.9885\n",
      "Epoch 8/15\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 0.3560 - accuracy: 0.9099 - precision_5: 0.8573 - recall_5: 0.9564 - val_loss: 0.0605 - val_accuracy: 0.9858 - val_precision_5: 1.0000 - val_recall_5: 0.9858\n",
      "Epoch 9/15\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 0.3131 - accuracy: 0.9159 - precision_5: 0.8672 - recall_5: 0.9574 - val_loss: 0.0691 - val_accuracy: 0.9834 - val_precision_5: 1.0000 - val_recall_5: 0.9834\n",
      "Epoch 10/15\n",
      "631/631 [==============================] - 3s 6ms/step - loss: 0.2695 - accuracy: 0.9224 - precision_5: 0.8755 - recall_5: 0.9622 - val_loss: 0.0838 - val_accuracy: 0.9805 - val_precision_5: 1.0000 - val_recall_5: 0.9805\n",
      "Epoch 11/15\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 0.2312 - accuracy: 0.9271 - precision_5: 0.8810 - recall_5: 0.9665 - val_loss: 0.0988 - val_accuracy: 0.9786 - val_precision_5: 1.0000 - val_recall_5: 0.9786\n",
      "Epoch 12/15\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 0.2019 - accuracy: 0.9309 - precision_5: 0.8855 - recall_5: 0.9699 - val_loss: 0.1152 - val_accuracy: 0.9769 - val_precision_5: 1.0000 - val_recall_5: 0.9769\n",
      "Epoch 13/15\n",
      "631/631 [==============================] - 4s 6ms/step - loss: 0.1805 - accuracy: 0.9330 - precision_5: 0.8881 - recall_5: 0.9716 - val_loss: 0.1320 - val_accuracy: 0.9758 - val_precision_5: 1.0000 - val_recall_5: 0.9758\n",
      "Epoch 14/15\n",
      "631/631 [==============================] - 3s 6ms/step - loss: 0.1679 - accuracy: 0.9343 - precision_5: 0.8906 - recall_5: 0.9716 - val_loss: 0.1428 - val_accuracy: 0.9746 - val_precision_5: 1.0000 - val_recall_5: 0.9746\n",
      "Epoch 15/15\n",
      "631/631 [==============================] - 4s 6ms/step - loss: 0.1619 - accuracy: 0.9349 - precision_5: 0.8922 - recall_5: 0.9709 - val_loss: 0.1519 - val_accuracy: 0.9737 - val_precision_5: 1.0000 - val_recall_5: 0.9737\n",
      "[Stage 3] Fine-tuning all layers...\n",
      "Epoch 1/5\n",
      "631/631 [==============================] - 7s 8ms/step - loss: 0.1336 - accuracy: 0.9460 - precision_6: 0.9106 - recall_6: 0.9741 - val_loss: 0.1435 - val_accuracy: 0.9764 - val_precision_6: 1.0000 - val_recall_6: 0.9764\n",
      "Epoch 2/5\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 0.1279 - accuracy: 0.9476 - precision_6: 0.9122 - recall_6: 0.9761 - val_loss: 0.1345 - val_accuracy: 0.9786 - val_precision_6: 1.0000 - val_recall_6: 0.9786\n",
      "Epoch 3/5\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 0.1257 - accuracy: 0.9482 - precision_6: 0.9123 - recall_6: 0.9774 - val_loss: 0.1386 - val_accuracy: 0.9776 - val_precision_6: 1.0000 - val_recall_6: 0.9776\n",
      "Epoch 4/5\n",
      "631/631 [==============================] - 5s 8ms/step - loss: 0.1248 - accuracy: 0.9482 - precision_6: 0.9124 - recall_6: 0.9773 - val_loss: 0.1325 - val_accuracy: 0.9795 - val_precision_6: 1.0000 - val_recall_6: 0.9795\n",
      "Epoch 5/5\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 0.1238 - accuracy: 0.9486 - precision_6: 0.9128 - recall_6: 0.9777 - val_loss: 0.1273 - val_accuracy: 0.9807 - val_precision_6: 1.0000 - val_recall_6: 0.9807\n",
      "[Stage 3] Weights saved to stage3.h5\n"
     ]
    }
   ],
   "source": [
    "# Stage 0: Attack vs Normal (From Scratch)\n",
    "s0 = balanced_sets[\"stage0_attack\"]\n",
    "model0 = train_stage(s0[\"X_train_bal\"], s0[\"y_train_bal\"], s0[\"X_test\"], s0[\"y_test\"],\n",
    "                     stage_name=\"Stage 0\", save_weights_path=\"stage0.h5\")\n",
    "\n",
    "# Stage 1: Recon vs Others (Transfer from Stage 0)\n",
    "s1 = balanced_sets[\"stage1_recon\"]\n",
    "model1 = train_stage(s1[\"X_train_bal\"], s1[\"y_train_bal\"], s1[\"X_test\"], s1[\"y_test\"],\n",
    "                     stage_name=\"Stage 1\", base_weights_path=\"stage0.h5\", save_weights_path=\"stage1.h5\")\n",
    "\n",
    "# Stage 2: Initial vs Others (Transfer from Stage 1)\n",
    "s2 = balanced_sets[\"stage2_initial\"]\n",
    "model2 = train_stage(s2[\"X_train_bal\"], s2[\"y_train_bal\"], s2[\"X_test\"], s2[\"y_test\"],\n",
    "                     stage_name=\"Stage 2\", base_weights_path=\"stage1.h5\", save_weights_path=\"stage2.h5\")\n",
    "\n",
    "# Stage 3: Exploit vs Others (Transfer from Stage 2)\n",
    "s3 = balanced_sets[\"stage3_exploit\"]\n",
    "model3 = train_stage(s3[\"X_train_bal\"], s3[\"y_train_bal\"], s3[\"X_test\"], s3[\"y_test\"],\n",
    "                     stage_name=\"Stage 3\", base_weights_path=\"stage2.h5\", save_weights_path=\"stage3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75aa0c19-6ef6-4c8e-b1ed-99627ada4dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stage 4] Loading base weights from stage3.h5...\n",
      "[Stage 4] Training frozen layers...\n",
      "Epoch 1/15\n",
      "845/845 [==============================] - 6s 6ms/step - loss: 0.9051 - accuracy: 0.6379 - precision_11: 0.6069 - recall_11: 0.5260 - val_loss: 1.1426 - val_accuracy: 0.5360 - val_precision_11: 1.0000 - val_recall_11: 0.5360\n",
      "Epoch 2/15\n",
      "845/845 [==============================] - 5s 6ms/step - loss: 0.6851 - accuracy: 0.6474 - precision_11: 0.6154 - recall_11: 0.5506 - val_loss: 0.8139 - val_accuracy: 0.5663 - val_precision_11: 1.0000 - val_recall_11: 0.5663\n",
      "Epoch 3/15\n",
      "845/845 [==============================] - 5s 6ms/step - loss: 0.5468 - accuracy: 0.6770 - precision_11: 0.6463 - recall_11: 0.6035 - val_loss: 0.6060 - val_accuracy: 0.6425 - val_precision_11: 1.0000 - val_recall_11: 0.6425\n",
      "Epoch 4/15\n",
      "845/845 [==============================] - 5s 6ms/step - loss: 0.4873 - accuracy: 0.7384 - precision_11: 0.6881 - recall_11: 0.7527 - val_loss: 0.5025 - val_accuracy: 0.8713 - val_precision_11: 1.0000 - val_recall_11: 0.8713\n",
      "Epoch 5/15\n",
      "845/845 [==============================] - 6s 7ms/step - loss: 0.4663 - accuracy: 0.7713 - precision_11: 0.6935 - recall_11: 0.8701 - val_loss: 0.4625 - val_accuracy: 0.9164 - val_precision_11: 1.0000 - val_recall_11: 0.9164\n",
      "Epoch 6/15\n",
      "845/845 [==============================] - 6s 7ms/step - loss: 0.4563 - accuracy: 0.7794 - precision_11: 0.6953 - recall_11: 0.8965 - val_loss: 0.4447 - val_accuracy: 0.9303 - val_precision_11: 1.0000 - val_recall_11: 0.9303\n",
      "Epoch 7/15\n",
      "845/845 [==============================] - 5s 6ms/step - loss: 0.4513 - accuracy: 0.7820 - precision_11: 0.6966 - recall_11: 0.9025 - val_loss: 0.4365 - val_accuracy: 0.9300 - val_precision_11: 1.0000 - val_recall_11: 0.9300\n",
      "Epoch 8/15\n",
      "845/845 [==============================] - 6s 7ms/step - loss: 0.4477 - accuracy: 0.7850 - precision_11: 0.6998 - recall_11: 0.9040 - val_loss: 0.4260 - val_accuracy: 0.9336 - val_precision_11: 1.0000 - val_recall_11: 0.9336\n",
      "Epoch 9/15\n",
      "845/845 [==============================] - 5s 6ms/step - loss: 0.4449 - accuracy: 0.7862 - precision_11: 0.7013 - recall_11: 0.9040 - val_loss: 0.4219 - val_accuracy: 0.9338 - val_precision_11: 1.0000 - val_recall_11: 0.9338\n",
      "Epoch 10/15\n",
      "845/845 [==============================] - 6s 7ms/step - loss: 0.4427 - accuracy: 0.7874 - precision_11: 0.7024 - recall_11: 0.9051 - val_loss: 0.4256 - val_accuracy: 0.9318 - val_precision_11: 1.0000 - val_recall_11: 0.9318\n",
      "Epoch 11/15\n",
      "845/845 [==============================] - 5s 6ms/step - loss: 0.4418 - accuracy: 0.7877 - precision_11: 0.7032 - recall_11: 0.9039 - val_loss: 0.4151 - val_accuracy: 0.9335 - val_precision_11: 1.0000 - val_recall_11: 0.9335\n",
      "Epoch 12/15\n",
      "845/845 [==============================] - 5s 6ms/step - loss: 0.4404 - accuracy: 0.7885 - precision_11: 0.7039 - recall_11: 0.9047 - val_loss: 0.4097 - val_accuracy: 0.9356 - val_precision_11: 1.0000 - val_recall_11: 0.9356\n",
      "Epoch 13/15\n",
      "845/845 [==============================] - 5s 5ms/step - loss: 0.4400 - accuracy: 0.7894 - precision_11: 0.7046 - recall_11: 0.9062 - val_loss: 0.4110 - val_accuracy: 0.9345 - val_precision_11: 1.0000 - val_recall_11: 0.9345\n",
      "Epoch 14/15\n",
      "845/845 [==============================] - 5s 5ms/step - loss: 0.4401 - accuracy: 0.7886 - precision_11: 0.7036 - recall_11: 0.9058 - val_loss: 0.4070 - val_accuracy: 0.9365 - val_precision_11: 1.0000 - val_recall_11: 0.9365\n",
      "Epoch 15/15\n",
      "845/845 [==============================] - 5s 6ms/step - loss: 0.4392 - accuracy: 0.7892 - precision_11: 0.7043 - recall_11: 0.9060 - val_loss: 0.4099 - val_accuracy: 0.9370 - val_precision_11: 1.0000 - val_recall_11: 0.9370\n",
      "[Stage 4] Fine-tuning all layers...\n",
      "Epoch 1/5\n",
      "845/845 [==============================] - 10s 9ms/step - loss: 0.3786 - accuracy: 0.8272 - precision_12: 0.7436 - recall_12: 0.9328 - val_loss: 0.3135 - val_accuracy: 0.9628 - val_precision_12: 1.0000 - val_recall_12: 0.9628\n",
      "Epoch 2/5\n",
      "845/845 [==============================] - 7s 8ms/step - loss: 0.3513 - accuracy: 0.8411 - precision_12: 0.7581 - recall_12: 0.9437 - val_loss: 0.3000 - val_accuracy: 0.9647 - val_precision_12: 1.0000 - val_recall_12: 0.9647\n",
      "Epoch 3/5\n",
      "845/845 [==============================] - 7s 9ms/step - loss: 0.3370 - accuracy: 0.8473 - precision_12: 0.7643 - recall_12: 0.9491 - val_loss: 0.2948 - val_accuracy: 0.9701 - val_precision_12: 1.0000 - val_recall_12: 0.9701\n",
      "Epoch 4/5\n",
      "845/845 [==============================] - 7s 8ms/step - loss: 0.3258 - accuracy: 0.8521 - precision_12: 0.7701 - recall_12: 0.9513 - val_loss: 0.2924 - val_accuracy: 0.9681 - val_precision_12: 1.0000 - val_recall_12: 0.9681\n",
      "Epoch 5/5\n",
      "845/845 [==============================] - 7s 8ms/step - loss: 0.3176 - accuracy: 0.8560 - precision_12: 0.7757 - recall_12: 0.9510 - val_loss: 0.2695 - val_accuracy: 0.9716 - val_precision_12: 1.0000 - val_recall_12: 0.9716\n",
      "[Stage 4] Weights saved to stage4.h5\n",
      "\n",
      "[Refinement (Install/Exploit)] Loading base weights from stage3.h5...\n",
      "[Refinement (Install/Exploit)] Training frozen layers...\n",
      "Epoch 1/15\n",
      "368/368 [==============================] - 4s 7ms/step - loss: 5.4508 - accuracy: 0.1897 - precision_13: 0.2089 - recall_13: 0.2953 - val_loss: 2.1254 - val_accuracy: 0.0131 - val_precision_13: 1.0000 - val_recall_13: 0.0131\n",
      "Epoch 2/15\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 3.7600 - accuracy: 0.1300 - precision_13: 0.0084 - recall_13: 0.0082 - val_loss: 2.7272 - val_accuracy: 0.0000e+00 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 3/15\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 2.3685 - accuracy: 0.1710 - precision_13: 8.2910e-05 - recall_13: 7.1751e-05 - val_loss: 3.1037 - val_accuracy: 0.0000e+00 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 4/15\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.6737 - accuracy: 0.3829 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 2.8861 - val_accuracy: 0.0000e+00 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 5/15\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3852 - accuracy: 0.4992 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 2.4725 - val_accuracy: 0.0000e+00 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 6/15\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.1669 - accuracy: 0.5294 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 2.0535 - val_accuracy: 0.0000e+00 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 7/15\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.9827 - accuracy: 0.5417 - precision_13: 0.0046 - recall_13: 1.4350e-04 - val_loss: 1.6734 - val_accuracy: 9.5666e-05 - val_precision_13: 1.0000 - val_recall_13: 9.5666e-05\n",
      "Epoch 8/15\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.8261 - accuracy: 0.5481 - precision_13: 0.1824 - recall_13: 0.0048 - val_loss: 1.3567 - val_accuracy: 0.0099 - val_precision_13: 1.0000 - val_recall_13: 0.0099\n",
      "Epoch 9/15\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.7000 - accuracy: 0.5577 - precision_13: 0.5314 - recall_13: 0.0399 - val_loss: 1.1022 - val_accuracy: 0.0365 - val_precision_13: 1.0000 - val_recall_13: 0.0365\n",
      "Epoch 10/15\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.6018 - accuracy: 0.5881 - precision_13: 0.6477 - recall_13: 0.1603 - val_loss: 0.9014 - val_accuracy: 0.1910 - val_precision_13: 1.0000 - val_recall_13: 0.1910\n",
      "Epoch 11/15\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5278 - accuracy: 0.6399 - precision_13: 0.6721 - recall_13: 0.3707 - val_loss: 0.7519 - val_accuracy: 0.5505 - val_precision_13: 1.0000 - val_recall_13: 0.5505\n",
      "Epoch 12/15\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4717 - accuracy: 0.7123 - precision_13: 0.7092 - recall_13: 0.5979 - val_loss: 0.6345 - val_accuracy: 0.7648 - val_precision_13: 1.0000 - val_recall_13: 0.7648\n",
      "Epoch 13/15\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4287 - accuracy: 0.7920 - precision_13: 0.7440 - recall_13: 0.8110 - val_loss: 0.5472 - val_accuracy: 0.9331 - val_precision_13: 1.0000 - val_recall_13: 0.9331\n",
      "Epoch 14/15\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.3960 - accuracy: 0.8366 - precision_13: 0.7608 - recall_13: 0.9224 - val_loss: 0.4780 - val_accuracy: 0.9668 - val_precision_13: 1.0000 - val_recall_13: 0.9668\n",
      "Epoch 15/15\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.3708 - accuracy: 0.8517 - precision_13: 0.7659 - recall_13: 0.9599 - val_loss: 0.4276 - val_accuracy: 0.9844 - val_precision_13: 1.0000 - val_recall_13: 0.9844\n",
      "[Refinement (Install/Exploit)] Fine-tuning all layers...\n",
      "Epoch 1/5\n",
      "368/368 [==============================] - 5s 10ms/step - loss: 0.2770 - accuracy: 0.8741 - precision_14: 0.7854 - recall_14: 0.9863 - val_loss: 0.2284 - val_accuracy: 0.9941 - val_precision_14: 1.0000 - val_recall_14: 0.9941\n",
      "Epoch 2/5\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.2579 - accuracy: 0.8782 - precision_14: 0.7898 - recall_14: 0.9892 - val_loss: 0.2318 - val_accuracy: 0.9968 - val_precision_14: 1.0000 - val_recall_14: 0.9968\n",
      "Epoch 3/5\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.2532 - accuracy: 0.8800 - precision_14: 0.7922 - recall_14: 0.9895 - val_loss: 0.2378 - val_accuracy: 0.9982 - val_precision_14: 1.0000 - val_recall_14: 0.9982\n",
      "Epoch 4/5\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.2508 - accuracy: 0.8805 - precision_14: 0.7930 - recall_14: 0.9893 - val_loss: 0.2147 - val_accuracy: 0.9990 - val_precision_14: 1.0000 - val_recall_14: 0.9990\n",
      "Epoch 5/5\n",
      "368/368 [==============================] - 4s 11ms/step - loss: 0.2489 - accuracy: 0.8815 - precision_14: 0.7950 - recall_14: 0.9884 - val_loss: 0.2080 - val_accuracy: 0.9989 - val_precision_14: 1.0000 - val_recall_14: 0.9989\n",
      "[Refinement (Install/Exploit)] Weights saved to stage_ie.h5\n"
     ]
    }
   ],
   "source": [
    "# Stage 4: Install vs Others (Transfer from Stage 3 + Class Weights)\n",
    "s4 = balanced_sets[\"stage4_install\"]\n",
    "\n",
    "cw_vals = compute_class_weight(class_weight=\"balanced\", classes=np.array([0, 1]), y=s4[\"y_train_bal\"])\n",
    "class_weights4 = {0: cw_vals[0], 1: cw_vals[1]}\n",
    "\n",
    "model4 = train_stage(s4[\"X_train_bal\"], s4[\"y_train_bal\"], s4[\"X_test\"], s4[\"y_test\"],\n",
    "                     stage_name=\"Stage 4\", base_weights_path=\"stage3.h5\", save_weights_path=\"stage4.h5\",\n",
    "                     class_weights=class_weights4)\n",
    "\n",
    "# --- Refinement Model: Install vs Exploit Binary ---\n",
    "# Filter data containing ONLY Install or Exploit\n",
    "ie_train = train_df[train_df[\"APT_stage\"].isin([\"Install\", \"Exploit\"])].copy()\n",
    "ie_test  = test_df[test_df[\"APT_stage\"].isin([\"Install\", \"Exploit\"])].copy()\n",
    "\n",
    "# Label: Install=1, Exploit=0\n",
    "ie_train[\"stage_label\"] = (ie_train[\"APT_stage\"] == \"Install\").astype(int)\n",
    "ie_test[\"stage_label\"]  = (ie_test[\"APT_stage\"] == \"Install\").astype(int)\n",
    "\n",
    "# Preprocess & Balance\n",
    "X_ie_train = to_dense(preprocessor.transform(ie_train[feature_cols]))\n",
    "y_ie_train = ie_train[\"stage_label\"].values\n",
    "\n",
    "sm_ie = SMOTE(random_state=42)\n",
    "X_ie_bal, y_ie_bal = sm_ie.fit_resample(X_ie_train, y_ie_train)\n",
    "\n",
    "# Calculate Weights\n",
    "cw_ie = compute_class_weight(\"balanced\", classes=np.array([0, 1]), y=y_ie_bal)\n",
    "class_weights_ie = {0: cw_ie[0], 1: cw_ie[1]}\n",
    "\n",
    "# Train Refinement Model\n",
    "model_ie = train_stage(X_ie_bal, y_ie_bal, to_dense(preprocessor.transform(ie_test[feature_cols])), ie_test[\"stage_label\"].values,\n",
    "                       stage_name=\"Refinement (Install/Exploit)\", \n",
    "                       base_weights_path=\"stage3.h5\",\n",
    "                       save_weights_path=\"stage_ie.h5\",\n",
    "                       class_weights=class_weights_ie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e13eec29-bc2b-4a5b-a016-0b88a90990f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cascade inference...\n",
      "2573/2573 [==============================] - 5s 2ms/step\n",
      "1524/1524 [==============================] - 3s 2ms/step\n",
      "1008/1008 [==============================] - 2s 2ms/step\n",
      "572/572 [==============================] - 1s 2ms/step\n",
      "571/571 [==============================] - 1s 2ms/step\n",
      "Inference complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Final Inference Logic ---\n",
    "X_all = test_df[feature_cols]\n",
    "X_all_proc = to_dense(preprocessor.transform(X_all))\n",
    "n_samples = len(test_df)\n",
    "\n",
    "# Default Prediction is \"Normal\"\n",
    "y_pred_final = np.array([\"Normal\"] * n_samples, dtype=object)\n",
    "\n",
    "# Thresholds (Tuned manually based on validation)\n",
    "THR = {\"Attack\": 0.55, \"Recon\": 0.50, \"Initial\": 0.50, \"Exploit\": 0.60, \"Install_Refined\": 0.15}\n",
    "\n",
    "print(\"Running cascade inference...\")\n",
    "\n",
    "# Step 1: Detect Attacks\n",
    "p0 = model0.predict(X_all_proc).ravel()\n",
    "mask_attack = p0 >= THR[\"Attack\"]\n",
    "attack_indices = np.where(mask_attack)[0]\n",
    "\n",
    "if len(attack_indices) > 0:\n",
    "    X_attack = X_all_proc[attack_indices]\n",
    "    \n",
    "    # Step 2: Detect Recon\n",
    "    p1 = model1.predict(X_attack).ravel()\n",
    "    recon_mask = p1 >= THR[\"Recon\"]\n",
    "    y_pred_final[attack_indices[recon_mask]] = \"Recon\"\n",
    "    \n",
    "    remaining_idx = attack_indices[~recon_mask]\n",
    "    \n",
    "    if len(remaining_idx) > 0:\n",
    "        X_rem = X_all_proc[remaining_idx]\n",
    "        \n",
    "        # Step 3: Detect Initial\n",
    "        p2 = model2.predict(X_rem).ravel()\n",
    "        initial_mask = p2 >= THR[\"Initial\"]\n",
    "        y_pred_final[remaining_idx[initial_mask]] = \"Initial\"\n",
    "        \n",
    "        # Remaining indices (Not Recon, Not Initial)\n",
    "        deep_idx = remaining_idx[~initial_mask]\n",
    "        \n",
    "        if len(deep_idx) > 0:\n",
    "            X_deep = X_all_proc[deep_idx]\n",
    "            \n",
    "            # Step 4: Detect Exploit (High confidence)\n",
    "            p3 = model3.predict(X_deep).ravel()\n",
    "            exploit_mask = p3 >= THR[\"Exploit\"]\n",
    "            y_pred_final[deep_idx[exploit_mask]] = \"Exploit\"\n",
    "            \n",
    "            # Step 5: Refine Exploit/Install\n",
    "            exploit_candidates = deep_idx[exploit_mask] \n",
    "            if len(exploit_candidates) > 0:\n",
    "                 p_ie = model_ie.predict(X_all_proc[exploit_candidates]).ravel()\n",
    "                 # If the refinement model says it's Install (>= 0.15), overwrite prediction\n",
    "                 install_mask = p_ie >= THR[\"Install_Refined\"]\n",
    "                 y_pred_final[exploit_candidates[install_mask]] = \"Install\"\n",
    "\n",
    "print(\"Inference complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8036e02c-3a65-453a-9d7a-9761c2e1989a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINAL CLASSIFICATION REPORT =====\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9050    0.8220    0.8615     37000\n",
      "       Recon     0.3722    0.6014    0.4598     10235\n",
      "     Initial     0.6070    0.7598    0.6749     11132\n",
      "     Exploit     0.9982    0.7920    0.8833     22960\n",
      "     Install     0.0000    0.0000    0.0000      1005\n",
      "\n",
      "    accuracy                         0.7678     82332\n",
      "   macro avg     0.5765    0.5950    0.5759     82332\n",
      "weighted avg     0.8134    0.7678    0.7819     82332\n",
      "\n",
      "\n",
      "Confusion Matrix (Rows=True, Cols=Predicted):\n",
      "[[30415  6052   531     2     0]\n",
      " [ 2856  6155  1216     7     1]\n",
      " [  216  2412  8458    23    23]\n",
      " [   92  1179  3494 18185    10]\n",
      " [   30   740   235     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation ---\n",
    "labels_order = [\"Normal\", \"Recon\", \"Initial\", \"Exploit\", \"Install\"]\n",
    "\n",
    "print(\"\\n===== FINAL CLASSIFICATION REPORT =====\\n\")\n",
    "print(classification_report(test_df[\"APT_stage\"], y_pred_final, labels=labels_order, digits=4))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Rows=True, Cols=Predicted):\")\n",
    "print(confusion_matrix(test_df[\"APT_stage\"], y_pred_final, labels=labels_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e606f-be2c-4c08-9206-c47e54456ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ded6c0-87e0-4902-8782-8dc979fcbd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8770a-0df3-41c2-8c04-cf38a64184da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d92e81-4808-4ff1-9784-e92d94326148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7804d-e784-4af3-ae44-6721c1d8304d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:apt_ml]",
   "language": "python",
   "name": "conda-env-apt_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
